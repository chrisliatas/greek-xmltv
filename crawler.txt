crawler-1  | 2025-12-31 13:05:06 [scrapy.utils.log] INFO: Scrapy 2.13.4 started (bot: xmltv)
crawler-1  | 2025-12-31 13:05:06 [scrapy.utils.log] INFO: Versions:
crawler-1  | {'lxml': '6.0.2',
crawler-1  |  'libxml2': '2.14.6',
crawler-1  |  'cssselect': '1.3.0',
crawler-1  |  'parsel': '1.10.0',
crawler-1  |  'w3lib': '2.3.1',
crawler-1  |  'Twisted': '24.7.0',
crawler-1  |  'Python': '3.11.14 (main, Dec 18 2025, 00:42:46) [GCC 15.2.0]',
crawler-1  |  'pyOpenSSL': '25.3.0 (OpenSSL 3.5.4 30 Sep 2025)',
crawler-1  |  'cryptography': '46.0.3',
crawler-1  |  'Platform': 'Linux-6.12.54-linuxkit-aarch64-with'}
crawler-1  | 2025-12-31 13:05:06 [scrapy.addons] INFO: Enabled addons:
crawler-1  | []
crawler-1  | 2025-12-31 13:05:06 [asyncio] DEBUG: Using selector: EpollSelector
crawler-1  | 2025-12-31 13:05:06 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
crawler-1  | 2025-12-31 13:05:06 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
crawler-1  | 2025-12-31 13:05:06 [scrapy.extensions.telnet] INFO: Telnet Password: 8d1862b130abf27c
crawler-1  | 2025-12-31 13:05:06 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/extensions/feedexport.py:455: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
crawler-1  |   exporter = cls(crawler)
crawler-1  | 
crawler-1  | 2025-12-31 13:05:06 [scrapy.middleware] INFO: Enabled extensions:
crawler-1  | ['scrapy.extensions.corestats.CoreStats',
crawler-1  |  'scrapy.extensions.telnet.TelnetConsole',
crawler-1  |  'scrapy.extensions.memusage.MemoryUsage',
crawler-1  |  'scrapy.extensions.feedexport.FeedExporter',
crawler-1  |  'scrapy.extensions.logstats.LogStats',
crawler-1  |  'scrapy.extensions.throttle.AutoThrottle']
crawler-1  | 2025-12-31 13:05:06 [scrapy.crawler] INFO: Overridden settings:
crawler-1  | {'AUTOTHROTTLE_ENABLED': True,
crawler-1  |  'BOT_NAME': 'xmltv',
crawler-1  |  'DOWNLOAD_DELAY': 3,
crawler-1  |  'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
crawler-1  |  'FEED_EXPORT_ENCODING': 'utf-8',
crawler-1  |  'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
crawler-1  |  'NEWSPIDER_MODULE': 'xmltv.spiders',
crawler-1  |  'SPIDER_MODULES': ['xmltv.spiders'],
crawler-1  |  'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
crawler-1  |                'like Gecko) Chrome/120.0.0.0 Safari/537.36'}
crawler-1  | Unhandled error in Deferred:
crawler-1  | 2025-12-31 13:05:06 [twisted] CRITICAL: Unhandled error in Deferred:
crawler-1  | 
crawler-1  | Traceback (most recent call last):
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 339, in crawl
crawler-1  |     return self._crawl(crawler, *args, **kwargs)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 343, in _crawl
crawler-1  |     d = crawler.crawl(*args, **kwargs)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 2287, in unwindGenerator
crawler-1  |     return _cancellableInlineCallbacks(gen)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 2197, in _cancellableInlineCallbacks
crawler-1  |     _inlineCallbacks(None, gen, status, _copy_context())
crawler-1  | --- <exception caught here> ---
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 2014, in _inlineCallbacks
crawler-1  |     result = context.run(gen.send, result)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 156, in crawl
crawler-1  |     self.engine = self._create_engine()
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 169, in _create_engine
crawler-1  |     return ExecutionEngine(self, lambda _: self.stop())
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/core/engine.py", line 113, in __init__
crawler-1  |     self.downloader: Downloader = downloader_cls(crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
crawler-1  |     DownloaderMiddlewareManager.from_crawler(crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/middleware.py", line 77, in from_crawler
crawler-1  |     return cls._from_settings(crawler.settings, crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/middleware.py", line 86, in _from_settings
crawler-1  |     mwcls = load_object(clspath)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/utils/misc.py", line 71, in load_object
crawler-1  |     mod = import_module(module)
crawler-1  |   File "/usr/local/lib/python3.11/importlib/__init__.py", line 126, in import_module
crawler-1  |     return _bootstrap._gcd_import(name[level:], package, level)
crawler-1  |   File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
crawler-1  |     
crawler-1  |   File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
crawler-1  |     
crawler-1  |   File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
crawler-1  |     
crawler-1  |   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
crawler-1  |     
crawler-1  |   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
crawler-1  |     
crawler-1  |   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
crawler-1  |     
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy_splash/__init__.py", line 4, in <module>
crawler-1  |     from .middleware import (
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy_splash/middleware.py", line 10, in <module>
crawler-1  |     from six.moves.urllib.parse import urljoin
crawler-1  | builtins.ModuleNotFoundError: No module named 'six'
crawler-1  | 
crawler-1  | 2025-12-31 13:05:06 [twisted] CRITICAL: 
crawler-1  | Traceback (most recent call last):
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 2014, in _inlineCallbacks
crawler-1  |     result = context.run(gen.send, result)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 156, in crawl
crawler-1  |     self.engine = self._create_engine()
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 169, in _create_engine
crawler-1  |     return ExecutionEngine(self, lambda _: self.stop())
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/core/engine.py", line 113, in __init__
crawler-1  |     self.downloader: Downloader = downloader_cls(crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
crawler-1  |     DownloaderMiddlewareManager.from_crawler(crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/middleware.py", line 77, in from_crawler
crawler-1  |     return cls._from_settings(crawler.settings, crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/middleware.py", line 86, in _from_settings
crawler-1  |     mwcls = load_object(clspath)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/utils/misc.py", line 71, in load_object
crawler-1  |     mod = import_module(module)
crawler-1  |   File "/usr/local/lib/python3.11/importlib/__init__.py", line 126, in import_module
crawler-1  |     return _bootstrap._gcd_import(name[level:], package, level)
crawler-1  |   File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
crawler-1  |   File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
crawler-1  |   File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
crawler-1  |   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
crawler-1  |   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
crawler-1  |   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy_splash/__init__.py", line 4, in <module>
crawler-1  |     from .middleware import (
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy_splash/middleware.py", line 10, in <module>
crawler-1  |     from six.moves.urllib.parse import urljoin
crawler-1  | ModuleNotFoundError: No module named 'six'
crawler-1  | 2025-12-31 13:05:06 [scrapy.addons] INFO: Enabled addons:
crawler-1  | []
crawler-1  | 2025-12-31 13:05:06 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
crawler-1  | 2025-12-31 13:05:06 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.unix_events._UnixSelectorEventLoop
crawler-1  | 2025-12-31 13:05:06 [scrapy.extensions.telnet] INFO: Telnet Password: 54298a8e9321317e
crawler-1  | 2025-12-31 13:05:06 [py.warnings] WARNING: /usr/local/lib/python3.11/site-packages/scrapy/extensions/feedexport.py:455: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details
crawler-1  |   exporter = cls(crawler)
crawler-1  | 
crawler-1  | 2025-12-31 13:05:06 [scrapy.middleware] INFO: Enabled extensions:
crawler-1  | ['scrapy.extensions.corestats.CoreStats',
crawler-1  |  'scrapy.extensions.telnet.TelnetConsole',
crawler-1  |  'scrapy.extensions.memusage.MemoryUsage',
crawler-1  |  'scrapy.extensions.feedexport.FeedExporter',
crawler-1  |  'scrapy.extensions.logstats.LogStats',
crawler-1  |  'scrapy.extensions.throttle.AutoThrottle']
crawler-1  | 2025-12-31 13:05:06 [scrapy.crawler] INFO: Overridden settings:
crawler-1  | {'AUTOTHROTTLE_ENABLED': True,
crawler-1  |  'BOT_NAME': 'xmltv',
crawler-1  |  'DOWNLOAD_DELAY': 3,
crawler-1  |  'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
crawler-1  |  'FEED_EXPORT_ENCODING': 'utf-8',
crawler-1  |  'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
crawler-1  |  'NEWSPIDER_MODULE': 'xmltv.spiders',
crawler-1  |  'SPIDER_MODULES': ['xmltv.spiders'],
crawler-1  |  'USER_AGENT': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, '
crawler-1  |                'like Gecko) Chrome/80.0.3987.106 Safari/537.36'}
crawler-1  | Unhandled error in Deferred:
crawler-1  | 2025-12-31 13:05:06 [twisted] CRITICAL: Unhandled error in Deferred:
crawler-1  | 
crawler-1  | Traceback (most recent call last):
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 339, in crawl
crawler-1  |     return self._crawl(crawler, *args, **kwargs)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 343, in _crawl
crawler-1  |     d = crawler.crawl(*args, **kwargs)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 2287, in unwindGenerator
crawler-1  |     return _cancellableInlineCallbacks(gen)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 2197, in _cancellableInlineCallbacks
crawler-1  |     _inlineCallbacks(None, gen, status, _copy_context())
crawler-1  | --- <exception caught here> ---
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 2014, in _inlineCallbacks
crawler-1  |     result = context.run(gen.send, result)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 156, in crawl
crawler-1  |     self.engine = self._create_engine()
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 169, in _create_engine
crawler-1  |     return ExecutionEngine(self, lambda _: self.stop())
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/core/engine.py", line 113, in __init__
crawler-1  |     self.downloader: Downloader = downloader_cls(crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
crawler-1  |     DownloaderMiddlewareManager.from_crawler(crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/middleware.py", line 77, in from_crawler
crawler-1  |     return cls._from_settings(crawler.settings, crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/middleware.py", line 86, in _from_settings
crawler-1  |     mwcls = load_object(clspath)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/utils/misc.py", line 71, in load_object
crawler-1  |     mod = import_module(module)
crawler-1  |   File "/usr/local/lib/python3.11/importlib/__init__.py", line 126, in import_module
crawler-1  |     return _bootstrap._gcd_import(name[level:], package, level)
crawler-1  |   File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
crawler-1  |     
crawler-1  |   File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
crawler-1  |     
crawler-1  |   File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
crawler-1  |     
crawler-1  |   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
crawler-1  |     
crawler-1  |   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
crawler-1  |     
crawler-1  |   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
crawler-1  |     
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy_splash/__init__.py", line 4, in <module>
crawler-1  |     from .middleware import (
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy_splash/middleware.py", line 10, in <module>
crawler-1  |     from six.moves.urllib.parse import urljoin
crawler-1  | builtins.ModuleNotFoundError: No module named 'six'
crawler-1  | 
crawler-1  | 2025-12-31 13:05:06 [twisted] CRITICAL: 
crawler-1  | Traceback (most recent call last):
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/twisted/internet/defer.py", line 2014, in _inlineCallbacks
crawler-1  |     result = context.run(gen.send, result)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 156, in crawl
crawler-1  |     self.engine = self._create_engine()
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/crawler.py", line 169, in _create_engine
crawler-1  |     return ExecutionEngine(self, lambda _: self.stop())
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/core/engine.py", line 113, in __init__
crawler-1  |     self.downloader: Downloader = downloader_cls(crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/core/downloader/__init__.py", line 109, in __init__
crawler-1  |     DownloaderMiddlewareManager.from_crawler(crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/middleware.py", line 77, in from_crawler
crawler-1  |     return cls._from_settings(crawler.settings, crawler)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/middleware.py", line 86, in _from_settings
crawler-1  |     mwcls = load_object(clspath)
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy/utils/misc.py", line 71, in load_object
crawler-1  |     mod = import_module(module)
crawler-1  |   File "/usr/local/lib/python3.11/importlib/__init__.py", line 126, in import_module
crawler-1  |     return _bootstrap._gcd_import(name[level:], package, level)
crawler-1  |   File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
crawler-1  |   File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
crawler-1  |   File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
crawler-1  |   File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
crawler-1  |   File "<frozen importlib._bootstrap_external>", line 940, in exec_module
crawler-1  |   File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy_splash/__init__.py", line 4, in <module>
crawler-1  |     from .middleware import (
crawler-1  |   File "/usr/local/lib/python3.11/site-packages/scrapy_splash/middleware.py", line 10, in <module>
crawler-1  |     from six.moves.urllib.parse import urljoin
crawler-1  | ModuleNotFoundError: No module named 'six'